# ğŸ§  Autonomous Product Catalog Cleaner & Manager

A production-grade application that uses LLMs to clean raw product catalog data, structure it, and provide an interface for viewing, updating, and managing product entries.

This project uses **LangChain + Groq LLMs** for intelligent field inference and **FastAPI + Streamlit** for full-stack interaction. The app is fully containerized using **Docker**.

---

## ğŸš€ Features

- ğŸ§¹ **Automatic product data cleaning** using LangGraph agents
- ğŸ“Š **Interactive dashboard** built with Streamlit
- ğŸ’¾ **Database-backed storage** via SQLModel (SQLite by default)
- ğŸ“¦ **View, search, edit, delete products**
- ğŸ§  Uses **LLM (Groq/Gemma)** to infer missing fields like brand, category, size
- ğŸ³ Fully containerized with Docker

---

## ğŸ§± Tech Stack

| Layer       | Tech                     |
|------------|--------------------------|
| LLM Agent   | LangGraph + Groq (Gemma) |
| Backend     | FastAPI (Pydantic v2)    |
| Frontend    | Streamlit                |
| ORM         | SQLModel (SQLite)        |
| Packaging   | Docker                   |
| Language    | Python 3.11+             |

---

## ğŸ—‚ï¸ Project Structure
```
Autonomous-Product-Catalog-UsingDB/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # FastAPI app
â”‚ â”œâ”€â”€ product_cleaner.py # LLM-powered cleaner
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ app.py # Streamlit dashboard
â”œâ”€â”€ models/
â”‚ â””â”€â”€ product_model.py # SQLModel database models
â”œâ”€â”€ schemas/
â”‚ â””â”€â”€ schema.py # Pydantic schemas for validation
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ tools.py # JSON extraction helpers
â”œâ”€â”€ Dockerfile # Unified backend + frontend Docker build
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


## âš™ï¸ Setup Instructions

### âœ… Clone the Repo

```bash
git clone https://github.com/samanwaya938/Automomus-Product-Catalogue-Cleaning-System.git
cd Automomus-Product-Catalogue-Cleaning-System
```

## ğŸ³ Run with Docker

### 1ï¸âƒ£ Build Docker Image

```bash
docker build -t (image_name):latest .
```

### 2ï¸âƒ£ Run the Container

```bash
docker run -p 8000:8000 -p 8501:8501 --env GROQ_API_KEY="Your API Key" (image_name)
```

## ğŸŒ Access the App
| Service      | URL                                                      |
| ------------ | -------------------------------------------------------- |
| Backend Docs | [http://localhost:8000/docs](http://localhost:8000/docs) |
| Streamlit UI | [http://localhost:8501](http://localhost:8501)           |


## ğŸ”Œ API Endpoints
| Method | Endpoint                | Description                |
| ------ | ----------------------- | -------------------------- |
| POST   | `/clean-product`        | Clean a raw product row    |
| POST   | `/save-product`         | Save cleaned product to DB |
| GET    | `/products`             | Get all products           |
| GET    | `/product/{product_id}` | Get a specific product     |
| PUT    | `/product/{product_id}` | Update a specific product  |
| DELETE | `/product/{product_id}` | Delete a specific product  |

## ğŸ§  How It Works
Upload a CSV of raw product data via the Streamlit dashboard.

Each row is sent to the LLM cleaner agent via FastAPI.

Missing fields like brand, category, color are inferred.

Cleaned data is previewed and can be saved to a database.

Users can search, update, or delete entries using the UI.

## ğŸ“¸ Screenshots (Add These)
![image](https://github.com/user-attachments/assets/29a5f076-320e-4513-a2f1-ffe0e9fb0a0b)
![image](https://github.com/user-attachments/assets/573ec62a-7848-4364-bff9-66971619dc5d)
![image](https://github.com/user-attachments/assets/62d2f4cb-5e0a-4e5d-b98d-a4ef2ee8af39)


## ğŸ”’ Security & Future Work
 * Role-based access for viewers/editors

 * Vector-based RAG for document search

 * Integration with product APIs

 * Optional login + JWT protection

## ğŸ’¡ Tips for Development
* Modify product_cleaner.py to enhance LLM prompts

* Change database from SQLite to Postgres by updating connection string in main.py

* Add unit tests for the cleaner agent and endpoints

* Use docker-compose.yml for multi-container setups (e.g., with Postgres)


## ğŸ“ License
MIT Â© 2025

## ğŸ“¬ Contact
GitHub: @samanwayaghosh938

Email: samanwayaghosh938@gmail.com

